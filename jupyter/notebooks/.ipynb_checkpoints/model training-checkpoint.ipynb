{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c602b3a-a3f5-4b68-8c1b-fd4ba39b079c",
   "metadata": {},
   "source": [
    "\n",
    "# Modelagem de um classificador binário de convenios  \n",
    "\n",
    "Todos os convênios que não estavam na situação 'em execução' foram classificados entre INSUCESSO e SUCESSO.  \n",
    "Foram classifcados como insucesso os convênios cuja situação era 'Prestação de Contas Rejeitada', 'Inadimplente', 'Convênio Rescindido' os demais foram classificados com não-insucesso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb4a0b-d487-4033-b571-a34a093f2108",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b206ab-84f1-4d94-8d6e-094136116321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "_ = nltk.download('rslp', quiet=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42335d-d37c-411f-ae04-2b2068975d17",
   "metadata": {},
   "source": [
    "## 2. Caregamento dos dados brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fdf510-4b32-4408-9ea3-819b211b167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convenios = pd.read_csv('../data_files/csv_files/convenios.csv.gz', decimal=',', sep=';', compression='gzip', encoding='utf-8')\n",
    "proponentes = pd.read_csv('../data_files/csv_files/proponentes.csv.gz', decimal=',', sep=';', compression='gzip', encoding='utf-8')\n",
    "emendas_convenios = pd.read_csv('../data_files/csv_files/emendas_convenios.csv.gz', decimal=',', sep=';', compression='gzip', encoding='utf-8')\n",
    "emendas = pd.read_csv('../data_files/csv_files/emendas.csv.gz', decimal=',', sep=';', compression='gzip', encoding='utf-8')\n",
    "movimento = pd.read_csv('../data_files/csv_files/movimento.csv.gz', decimal=',', sep=';', compression='gzip', encoding='utf-8')\n",
    "fornecedores = pd.read_csv('../data_files/csv_files/fornecedores.csv.gz', decimal=',', sep=';', compression='gzip', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699e1df-64ce-4ea7-b027-49853462ed73",
   "metadata": {},
   "source": [
    "## 3. Seleção dos convênios\n",
    "> Apenas convenios que não estão em execução e cujo ano do fim da vigência é 2017 ou posterior. \n",
    ">\n",
    "> Foram considerados como insucesso convênios cuja situação é 'Prestação de Contas Rejeitada', 'Inadimplente' ou 'Convênio Rescindido'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa9c3d1-f247-4a4c-82b9-e2ba10da0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "convenios = convenios[(convenios['DIA_FIM_VIGENC_CONV'].astype('datetime64[ns]').dt.year >=2017) & (convenios['DIA_PUBL_CONV'].notna())].copy()\n",
    "convenios = convenios[convenios['SIT_CONVENIO'].str.upper()!='EM EXECUÇÃO']\n",
    "convenios['INSUCESSO'] = 0\n",
    "convenios.loc[convenios['SIT_CONVENIO'].isin(['Prestação de Contas Rejeitada', 'Inadimplente', 'Convênio Rescindido']), 'INSUCESSO'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03c242-987f-4c51-ae5e-4985e5638395",
   "metadata": {},
   "source": [
    "## 4. Definição da classe TextTransformer  \n",
    "> Esta classe realiza a o agrupamento (clustering) de textos com o algorítimo K-Means.  \n",
    "> A finalidade aqui é representar os textos da coluna 'OBJETO_PROPOSTA' em classes designadas por números inteiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6415766-8dd4-4fb7-b6fa-5d7261dde0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, n_clusters=5, stop_words=[], accented=[]):\n",
    "        \n",
    "        self.__n_clusters__ = n_clusters\n",
    "        self.__stop_words__ = stop_words\n",
    "        self.__accented__ = accented\n",
    "        self.labels_ = None\n",
    "        self.__vectorizer__ = TfidfVectorizer(use_idf=True)\n",
    "        self.__clusterer__ = KMeans(n_clusters=self.__n_clusters__, random_state=0)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        X = self.__preprocessing__(X)\n",
    "        X = self.__vectorizer__.fit_transform(X)\n",
    "        self.__clusterer__ = self.__clusterer__.fit(X)\n",
    "        self.labels_ = self.__clusterer__.labels_\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \n",
    "        X = self.__preprocessing__(X)\n",
    "        X = self.__vectorizer__.fit_transform(X)\n",
    "        X = self.__clusterer__.fit_transform(X)\n",
    "        self.labels_ = self.__clusterer__.labels_\n",
    "        return X\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        \n",
    "        X = self.__preprocessing__(X)\n",
    "        X = self.__vectorizer__.fit_transform(X)\n",
    "        y = self.__clusterer__.fit_predict(X)\n",
    "        self.labels_ = self.__clusterer__.labels_\n",
    "        return y\n",
    "    \n",
    "    def transform(self, X):        \n",
    "        \n",
    "        X = self.__preprocessing__(X)\n",
    "        X = self.__vectorizer__.transform(X)\n",
    "        X = self.__clusterer__.transform(X)\n",
    "        return X\n",
    "                       \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return_unique = False\n",
    "        if type(X)==str:\n",
    "            X = [X]\n",
    "            return_unique = True\n",
    "        \n",
    "        X = self.__preprocessing__(X)\n",
    "        X = self.__vectorizer__.transform(X)\n",
    "        y = self.__clusterer__.predict(X)\n",
    "        y = y[0] if return_unique else y\n",
    "        return y\n",
    "    \n",
    "    def __preprocessing__(self, X):\n",
    "        \n",
    "        X = [' '.join(self.__text_preprocessing__(t)) for t in X]\n",
    "        return X\n",
    "    \n",
    "    def __stemming__(self, tokens):  \n",
    "        \n",
    "        stemmer = nltk.stem.RSLPStemmer()\n",
    "        return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    def __remove_accents__(self, text):\n",
    "        \n",
    "        for idx in self.__accented__.index:\n",
    "            text = text.replace(self.__accented__['char_acc'][idx], self.__accented__['char_norm'][idx]) \n",
    "        return text\n",
    "\n",
    "    def __text_preprocessing__(self, text):\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = self.__remove_accents__(text)\n",
    "        tokens = re.findall('[a-z]+', text)\n",
    "        tokens = filter(lambda w: w is not None, map(lambda w: None if w in self.__stop_words__ or len(w)==1 else w , tokens))\n",
    "        tokens = self.__stemming__(tokens)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e33bd-ef73-4586-975f-48e6dbfe6209",
   "metadata": {},
   "source": [
    "## 5. Definição da função transform_dataset  \n",
    "> Esta função realiza a conversão dos dados distribuídos nas tabelas (dataframes carregados) para um dataset (conjunto de dados).\n",
    "> A finalidade aqui obter um conjunto de dados no formato apropriado para os algorítimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de7f031-6d00-48b6-a009-779596cd4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(convenios, proponentes, emendas, emendas_convenios, fornecedores, movimento, ylabel=False, ylabel_name='INSUCESSO'):\n",
    "\n",
    "    ibge = proponentes[['IDENTIF_PROPONENTE', 'CODIGO_IBGE']].copy()\n",
    "\n",
    "    selected_columns = ['VL_REPASSE_CONV', 'VL_CONTRAPARTIDA_CONV', 'VALOR_EMENDA_CONVENIO',\n",
    "           'OBJETO_PROPOSTA', 'COD_ORGAO', 'COD_ORGAO_SUP', 'NATUREZA_JURIDICA',\n",
    "           'MODALIDADE', 'IDENTIF_PROPONENTE', 'COM_EMENDAS']\n",
    "\n",
    "    features_columns = ['NR_CONVENIO', *selected_columns]\n",
    "    if ylabel:\n",
    "        features_columns += [ylabel_name]\n",
    "\n",
    "    convenios_ = convenios[features_columns].copy()\n",
    "\n",
    "    principais_parlamentares = get_principais_parlamentares(emendas=emendas, emendas_convenios=emendas_convenios, convenios_list=convenios_['NR_CONVENIO'].to_list())\n",
    "    principais_fornecedores = get_principais_fornecedores(movimento=movimento, fornecedores=fornecedores, convenios_list=convenios_['NR_CONVENIO'].to_list())\n",
    "\n",
    "    dataset = pd.merge(convenios_, ibge, how='inner', on=['IDENTIF_PROPONENTE'], left_index=False, right_index=False)\n",
    "\n",
    "    dataset = pd.merge(dataset, principais_parlamentares, how='left', on=['NR_CONVENIO'], left_index=False, right_index=False)\n",
    "\n",
    "    dataset = pd.merge(dataset, principais_fornecedores, how='left', on=['NR_CONVENIO'], left_index=False, right_index=False)\n",
    "\n",
    "    dataset = dataset.fillna('NAO APLICAVEL')\n",
    "\n",
    "    Xdtypes = {'VL_REPASSE_CONV': 'float64', 'VL_CONTRAPARTIDA_CONV': 'float64', \n",
    "               'VALOR_EMENDA_CONVENIO': 'float64', 'OBJETO_PROPOSTA': 'object', \n",
    "               'COD_ORGAO': 'int64', 'COD_ORGAO_SUP': 'int64', 'NATUREZA_JURIDICA': 'object', \n",
    "               'MODALIDADE': 'object', 'IDENTIF_PROPONENTE': 'object', 'COM_EMENDAS': 'object',\n",
    "               'CODIGO_IBGE': 'int64', 'PRINCIPAL_PARLAMENTAR': 'object', \n",
    "               'PRINCIPAL_FORNECEDOR': 'object'}\n",
    "\n",
    "    return dataset.astype(Xdtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45d05aa-f9ab-491e-a10b-567b2439ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principais_parlamentares( emendas, emendas_convenios, convenios_list):\n",
    "\n",
    "    convenios_repasses_emendas = emendas_convenios.loc[emendas_convenios['NR_CONVENIO'].isin(convenios_list)].copy()\n",
    "    convenios_repasses_emendas['rank'] = convenios_repasses_emendas.groupby(by=['NR_CONVENIO'])['VALOR_REPASSE_EMENDA'].rank(ascending=False, method='min')\n",
    "    convenios_repasses_emendas = convenios_repasses_emendas.loc[convenios_repasses_emendas['rank']==1, ['NR_CONVENIO', 'NR_EMENDA']]\n",
    "    convenios_parlamentares = pd.merge(convenios_repasses_emendas, emendas, on=['NR_EMENDA'], left_index=False, right_index=False)\n",
    "    convenios_parlamentares = convenios_parlamentares[['NR_CONVENIO', 'NOME_PARLAMENTAR']]\n",
    "    convenios_parlamentares.columns = ['NR_CONVENIO', 'PRINCIPAL_PARLAMENTAR']\n",
    "    convenios_parlamentares = convenios_parlamentares.groupby(by=['NR_CONVENIO']).max().reset_index()\n",
    "\n",
    "    return convenios_parlamentares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6175759b-caf6-4acc-8ac2-9a91a72f517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principais_fornecedores(movimento, fornecedores, convenios_list):\n",
    "\n",
    "    movimento_exec = movimento.loc[movimento['NR_CONVENIO'].isin(convenios_list)].copy()\n",
    "    movimento_exec = movimento_exec[movimento_exec['TIPO_MOV']=='P']\n",
    "    convenios_fornecedores = movimento_exec[['NR_CONVENIO', 'FORNECEDOR_ID', 'VALOR_MOV']].groupby(by=['NR_CONVENIO', 'FORNECEDOR_ID']).sum().reset_index().copy()\n",
    "    convenios_fornecedores['rank'] = convenios_fornecedores.groupby(by=['NR_CONVENIO'])['VALOR_MOV'].rank(ascending=False, method='min')\n",
    "    convenios_fornecedores = convenios_fornecedores.loc[convenios_fornecedores['rank']==1, ['NR_CONVENIO', 'FORNECEDOR_ID']]\n",
    "    convenios_fornecedores = pd.merge(convenios_fornecedores, fornecedores, on=['FORNECEDOR_ID'], left_index=False, right_index=False)\n",
    "    convenios_fornecedores = convenios_fornecedores.sort_values(['NR_CONVENIO', 'IDENTIF_FORNECEDOR'], ascending=False)\n",
    "    convenios_fornecedores = convenios_fornecedores[['NR_CONVENIO', 'IDENTIF_FORNECEDOR']]\n",
    "    convenios_fornecedores.columns = ['NR_CONVENIO', 'PRINCIPAL_FORNECEDOR']\n",
    "    convenios_fornecedores = convenios_fornecedores.groupby(by=['NR_CONVENIO']).max().reset_index()\n",
    "\n",
    "    return convenios_fornecedores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef2858-4973-4adc-b4ae-35c1b9b07371",
   "metadata": {},
   "source": [
    "## 6. Definição da função make_transformers  \n",
    "> Esta função prepara um conjunto transformadores (transformers) para converter e normalizar os dados.   \n",
    "> 1. Para os dados categóricos foi utilizado o codificador (encoder) 'OneHotEncoder'.  \n",
    "> 2. Os dados contínuos foram normalizados com o 'PowerTransformer'.  \n",
    ">\n",
    "> A função make_transformers recebe um dataframe com os dados brutos e retorna um dicionário contendo todos os transformadores treinados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b899f8a3-12b7-49a8-b25e-3bf9487c2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transformers(X, stop_words_path, accented_path):\n",
    "\n",
    "    accented = pd.read_csv(accented_path, compression='gzip', sep=';', encoding='utf-8')\n",
    "    stop_words = pd.read_csv(stop_words_path, compression='gzip', encoding='utf-8', header=None)[0].tolist()\n",
    "    data = X.copy()\n",
    "    text_clusterer = TextTransformer(n_clusters=50, stop_words=stop_words, accented=accented).fit(data['OBJETO_PROPOSTA'])\n",
    "    data['OBJETO_PROPOSTA'] = text_clusterer.predict(data['OBJETO_PROPOSTA'])\n",
    "    data['OBJETO_PROPOSTA'] = data['OBJETO_PROPOSTA'].astype('int64')\n",
    "\n",
    "    data_categorical_parlamentar = data.pop('PRINCIPAL_PARLAMENTAR').to_frame()\n",
    "    data_categorical_fornecedor = data.pop('PRINCIPAL_FORNECEDOR').to_frame()\n",
    "\n",
    "    data_categorical_object = data.select_dtypes(include=['object'])\n",
    "    data_categorical_int = data.select_dtypes(include=['int64'])\n",
    "    data_value = data.select_dtypes(include='float64')\n",
    "\n",
    "    transformers = {}\n",
    "    transformers['TEXT_CLUSTERER'] = text_clusterer\n",
    "    transformers['VALUE'] = PowerTransformer().fit(data_value)\n",
    "    transformers['CATEGORICAL_OBJECT'] = OneHotEncoder(handle_unknown='ignore').fit(data_categorical_object)\n",
    "    transformers['CATEGORICAL_INT'] = OneHotEncoder(handle_unknown='infrequent_if_exist', max_categories=500).fit(data_categorical_int)\n",
    "    transformers['CATEGORICAL_PARLAMENTAR'] = OneHotEncoder(handle_unknown='infrequent_if_exist', max_categories=500).fit(data_categorical_parlamentar)\n",
    "    transformers['CATEGORICAL_FORNECEDOR'] = OneHotEncoder(handle_unknown='infrequent_if_exist', max_categories=500).fit(data_categorical_fornecedor)\n",
    "\n",
    "    return transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dbf406-c06a-40ef-8f9b-a5d8dfc466d8",
   "metadata": {},
   "source": [
    "## 7. Definição da função data_preparation  \n",
    "> Esta função utiliza os transformadores (transformers) para converter e normalizar os dados.  \n",
    "> A finalidade aqui é adequar os dados para serem utilizados nos algorítimos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8caa302a-e68d-4c6c-a780-8c87076e2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(transformers, X):\n",
    "\n",
    "    data = X.copy()\n",
    "    data['OBJETO_PROPOSTA'] = transformers['TEXT_CLUSTERER'].predict(data['OBJETO_PROPOSTA'])\n",
    "    data['OBJETO_PROPOSTA'] = data['OBJETO_PROPOSTA'].astype('int64')\n",
    "\n",
    "    data_categorical_parlamentar = data.pop('PRINCIPAL_PARLAMENTAR').to_frame()\n",
    "    data_categorical_fornecedor = data.pop('PRINCIPAL_FORNECEDOR').to_frame()\n",
    "\n",
    "    data_categorical_object = data.select_dtypes(include=['object'])\n",
    "    data_categorical_int = data.select_dtypes(include=['int64'])\n",
    "    data_value = data.select_dtypes(include='float64')\n",
    "\n",
    "    value_codes = transformers['VALUE'].transform(data_value)\n",
    "    value_feature_names = transformers['VALUE'].feature_names_in_\n",
    "    data_value = pd.DataFrame(value_codes, columns=value_feature_names).astype('float64')\n",
    "\n",
    "    categorical_object_codes = transformers['CATEGORICAL_OBJECT'].transform(data_categorical_object).toarray()\n",
    "    categorical_object_feature_names= transformers['CATEGORICAL_OBJECT'].get_feature_names_out()\n",
    "    data_categorical_object = pd.DataFrame(categorical_object_codes, columns=categorical_object_feature_names).astype('float64')\n",
    "\n",
    "    categorical_int_codes = transformers['CATEGORICAL_INT'].transform(data_categorical_int).toarray()\n",
    "    categorical_int_feature_names= transformers['CATEGORICAL_INT'].get_feature_names_out()\n",
    "    data_categorical_int = pd.DataFrame(categorical_int_codes, columns=categorical_int_feature_names).astype('float64')\n",
    "\n",
    "    parlamentar_codes = transformers['CATEGORICAL_PARLAMENTAR'].transform(data_categorical_parlamentar).toarray()\n",
    "    parlamentar_feature_names= transformers['CATEGORICAL_PARLAMENTAR'].get_feature_names_out()\n",
    "    data_categorical_parlamentar = pd.DataFrame(parlamentar_codes, columns=parlamentar_feature_names).astype('float64')\n",
    "\n",
    "    fornecedor_codes = transformers['CATEGORICAL_FORNECEDOR'].transform(data_categorical_fornecedor).toarray()\n",
    "    fornecedor_feature_names= transformers['CATEGORICAL_FORNECEDOR'].get_feature_names_out()\n",
    "    data_categorical_fornecedor = pd.DataFrame(fornecedor_codes, columns=fornecedor_feature_names).astype('float64')\n",
    "\n",
    "    return pd.concat([data_value, data_categorical_object, data_categorical_int,\n",
    "                      data_categorical_parlamentar, data_categorical_fornecedor], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33a48a-a860-43b7-8944-6a892cac90ae",
   "metadata": {},
   "source": [
    "## 8. Definição da função make_train_test_base  \n",
    "> Esta função divide os dados originais em duas partes: uma para treino e outra para testes (avaliação).  \n",
    "> A finalidade aqui é deixar essas bases disponíveis para os procedimwentos de treino e avaliação.  \n",
    "> Esta função também se encarrega da conversão da coluna 'OBJETO_PROPOSTA' em agrupamentos (clusters), o que a transforma em uma coluna com dados categóricos passíveis de serem manipulados pelos algorítimos de normalização e classificação.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6269702-f25d-41e4-ad40-d907daee1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_bases(**tables):\n",
    "    \n",
    "    assert not tables or set(tables.keys()) == {'convenios', 'proponentes', 'emendas', 'emendas_convenios', \n",
    "    'fornecedores', 'movimento'}, '''Named arguments, if provided, must be: convenios, emendas, emendas_convenios, fornecedores, movimento'''\n",
    "\n",
    "    ylabel_name='INSUCESSO'\n",
    "    print('transforming tables into dataset ... ', end='')\n",
    "    data = transform_dataset(**tables, ylabel=True, ylabel_name=ylabel_name)\n",
    "    data = data.drop(['NR_CONVENIO'], axis=1)\n",
    "    print(f'{len(data)} linhas')\n",
    "\n",
    "    print('balancing ... ', end='')\n",
    "    data = data.sample(frac=1.).reset_index(drop=True)\n",
    "    print(f'{len(data)} linhas')\n",
    "    q0 = len(data[data[ylabel_name]==0])\n",
    "    q1 = len(data[data[ylabel_name]==1])\n",
    "    q = q0 if q0<q1 else q1\n",
    "\n",
    "    X = pd.concat([data[data[ylabel_name]==0].iloc[0:q], data[data[ylabel_name]==1].iloc[0:q]], sort=False)\n",
    "    y = X[[ylabel_name]]\n",
    "    X = pd.concat([data[data[ylabel_name]==0].iloc[0:q], data[data[ylabel_name]==1].iloc[0:q]], sort=False)\n",
    "    #rest = data[~data.index.isin(X.index)]\n",
    "    print(f'{len(X)} linhas')\n",
    "\n",
    "    print('spliting ... ', end='')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "    print(f'{len(X_train)} linhas de treino', f'{len(X_test)} linhas de teste')\n",
    "\n",
    "    print('saving train and test datasets ... ', end='')\n",
    "    X_train.to_csv('./datasets/convenios_train.tsv.gz', compression='gzip', sep='\\t', encoding='utf-8', index=False)\n",
    "    X_test.to_csv('./datasets/convenios_test.tsv.gz', compression='gzip', sep='\\t', encoding='utf-8', index=False)\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68907744-8a88-4665-b2f3-fe8d8a06676b",
   "metadata": {},
   "source": [
    "## 9. Definição da função get_tuned_estimator  \n",
    "> Esta função realiza a seleção de hiperparâmetros (tuning).  \n",
    "> A finalidade aqui é selecionar os melhores dentre um conjunto de hiperparâmetros escolhidos para o modelo informado.  \n",
    "> Esta função retorna o melhor score obtido e os hiperparâmetros correspondentes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf5fed6-885d-4418-80be-dd6990182f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuned_estimator(X, y, estimator, param_dist, scoring='accuracy'):\n",
    "    rand = GridSearchCV(estimator, param_dist, cv=10, refit=True, scoring=scoring)\n",
    "    rand.fit(X, y['INSUCESSO'])\n",
    "\n",
    "    return rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ce477-aeab-4345-9529-499a0c102d14",
   "metadata": {},
   "source": [
    "## 10. Definição da função load_bases  \n",
    "> Esta função é utilizada para a carga das bases de treino e de teste.  \n",
    "> A finalidade aqui é propiciar um meio único e confiável de se realizar o carregamento das bases de treino e de teste.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a371ef-9e31-4061-88ba-8ed4e03d4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bases(type='both', ylabel_name='INSUCESSO'):\n",
    "\n",
    "    assert type in ['train', 'test', 'both']\n",
    "\n",
    "    result = []\n",
    "    if type.lower() in ['train', 'both']:\n",
    "        train_base = pd.read_csv('./datasets/convenios_train.tsv.gz', compression='gzip', sep='\\t', encoding='utf-8')\n",
    "        X_train = train_base.drop([ylabel_name], axis=1)\n",
    "        y_train = train_base[[ylabel_name]]\n",
    "        result += [X_train, y_train]\n",
    "\n",
    "    if type.lower() in ['test', 'both']:\n",
    "        test_base = pd.read_csv('./datasets/convenios_test.tsv.gz', compression='gzip', sep='\\t', encoding='utf-8')\n",
    "        X_test = test_base.drop([ylabel_name], axis=1)\n",
    "        y_test = test_base[[ylabel_name]]\n",
    "        result += [X_test, y_test]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19c88f-e78a-4ea3-8bbc-d5d095f3e4a8",
   "metadata": {},
   "source": [
    "## 11. Definição da função de aferição de métricas  \n",
    "> A finalidade é calcular as métricas do modelo e fornecer os resultados em formato dicionário e texto formatado\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df2eeea9-964c-438e-86f6-e5cc740ce97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_report(y_true, y_pred, target_names=None, title='Classification Report'):\n",
    "    metrics = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    metrics = {target_names[0]: {**metrics[target_names[0]]}, target_names[1]: {**metrics[target_names[1]]}, 'accuracy': metrics['accuracy']}\n",
    "    report = f'''\n",
    "    {title}\n",
    "    -------------------------------------------\n",
    "    \\t\\t{target_names[0]}\\t\\t{target_names[1]}\n",
    "    -------------------------------------------\n",
    "    recall\\t{round(metrics[target_names[0]][\"recall\"], 2)}\\t\\t{round(metrics[target_names[1]][\"recall\"], 2)}\n",
    "    precision\\t{round(metrics[target_names[0]][\"precision\"], 2)}\\t\\t{round(metrics[target_names[1]][\"precision\"], 2)}\n",
    "    f1-score\\t{round(metrics[target_names[0]][\"f1-score\"], 2)}\\t\\t{round(metrics[target_names[1]][\"f1-score\"], 2)}\n",
    "    support\\t{round(metrics[target_names[0]][\"support\"], 2)}\\t\\t{round(metrics[target_names[1]][\"support\"], 2)}\n",
    "    -------------------------------------------\n",
    "    accuracy\\t\\t{round(metrics[\"accuracy\"], 2)}'''\n",
    "    \n",
    "    return metrics, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348bf73-2fdc-4d37-935d-29b98695b7c3",
   "metadata": {},
   "source": [
    "## 12. Criação das bases de treino e de teste\n",
    "> Executado apenas quando se quer criar/recriar as bases de treino e teste a partir dos dados originais.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d8f5383-8920-4bb4-b92b-1b3a1da3bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming tables into dataset ... 73789 linhas\n",
      "balancing ... 0 linhas\n",
      "spliting ... "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.33 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_train_test_bases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvenios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvenios\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproponentes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproponentes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memendas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memendas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memendas_convenios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memendas_convenios\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfornecedores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfornecedores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovimento\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmovimento\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mmake_train_test_bases\u001b[0;34m(**tables)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m linhas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspliting ... \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.33\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m linhas de treino\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m linhas de teste\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaving train and test datasets ... \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2433\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2430\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2432\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2433\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2111\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2108\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2115\u001b[0m     )\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.33 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "make_train_test_bases(convenios=convenios, proponentes=proponentes, emendas=emendas, emendas_convenios=emendas_convenios, fornecedores=fornecedores, movimento=movimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576df07a-79f8-4d9a-a0f0-225e718ef0b7",
   "metadata": {},
   "source": [
    "## 13. Liberação de memória com garbage collector\n",
    "> Remoção de dataframes não mais necessários.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc9b97-e85d-41a7-aca7-bfe7cfe8d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del convenios\n",
    "del proponentes\n",
    "del emendas_convenios\n",
    "del emendas\n",
    "del movimento\n",
    "del fornecedores \n",
    "\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609dd41-6a80-43d1-be89-3134f3f85ae7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 14. Carregamento da base de treino e preparação dos dados \n",
    "> A função load_bases é utilizado para carregar a base de treino. Em seguida:  \n",
    "> 1. A função make_transformers é utilizada para preparar os trasnformadores (normalizadores e codificadores). \n",
    ">\n",
    "> 2. Também é instanciado um objeto PCA (principal component analysis) cuja finalidade é realizar a redução da dimensionalidade do modelo por meio do conceito de autovalores e autovetores.\n",
    ">\n",
    "> 3. Por fim, são aplicadas a preparação dos dados e a transformação PCA, de modo a se obter um cujunto de características (features) adquado e suficiente ao processo de teinamento do classificador.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c1079-0eeb-4ed1-a47e-de0d847818a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test bases loading\n",
    "X_train, y_train = load_bases(type='train')\n",
    "\n",
    "#data preparation\n",
    "transformers = make_transformers(X_train, stop_words_path='./datasets/stopwords.txt.gz', accented_path='./datasets/accented.txt.gz')\n",
    "pca = PCA(n_components=700)\n",
    "\n",
    "X_train = data_preparation(transformers, X_train)\n",
    "pca.fit(X_train, y_train)\n",
    "X_train = pca.transform(X_train)\n",
    "print(f'Explained Variance Ratio ---> {round(sum(pca.explained_variance_ratio_)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ef255-48d7-48ef-a000-18537c168d43",
   "metadata": {},
   "source": [
    "## 15. Seleção hiperparâmetros dos algorítimos candidatos (tuning)\n",
    "> Cada algorítimo candidato é treinado e avaliado com cross-validation por meio da função get_tuned_estimator, que utiliza o GridSearchCV. Neste caso o score a ser observado é o de recall (revocação), já que se pretende detectar o maior número possível de convênios com insucesso.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966fecc-e509-4f46-a142-48472df90657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimators_list = [\n",
    "    {\n",
    "     'name': 'GNB',\n",
    "     'estimator': GaussianNB(),\n",
    "     'param_dist': {\n",
    "             'var_smoothing': [1e-12, 1e-15, 1e-20]\n",
    "              }\n",
    "\n",
    "    },\n",
    "\n",
    "    {\n",
    "     'name': 'DTR',\n",
    "     'estimator': DecisionTreeClassifier(),\n",
    "     'param_dist': {\n",
    "             'criterion': ['gini', 'entropy'],\n",
    "              }\n",
    "\n",
    "    },\n",
    "\n",
    "    \n",
    "    {\n",
    "     'name': 'SVC',\n",
    "     'estimator': SVC(),\n",
    "     'param_dist': { \n",
    "                 'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "                 'gamma':[2], \n",
    "                 'C': [1]\n",
    "                 }\n",
    "    },\n",
    "    \n",
    "    {\n",
    "     'name': 'ADA',\n",
    "     'estimator': AdaBoostClassifier(),\n",
    "     'param_dist': {\n",
    "             'n_estimators': [25, 50],\n",
    "             'learning_rate': [1.0],\n",
    "              }\n",
    "\n",
    "    },\n",
    "    \n",
    "    {\n",
    "     'name': 'MLP',\n",
    "     'estimator': MLPClassifier(),\n",
    "     'param_dist': {\n",
    "                  'hidden_layer_sizes': [(10,), (20,), (30,), (10, 10), (10, 20), (10, 30)],\n",
    "                  'alpha': [0.0001], \n",
    "                  'shuffle': [False],\n",
    "                  'activation': ['relu'],\n",
    "                  'max_iter': [2000]\n",
    "                  }\n",
    "    },\n",
    "    \n",
    "    {\n",
    "     'name': 'RFC',\n",
    "     'estimator': RandomForestClassifier(),\n",
    "     'param_dist': {\n",
    "                  'n_estimators': [25, 50],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_features': [None]\n",
    "                  }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfeb58-2b76-48c2-bf3b-afb73e341803",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'recall'\n",
    "classifiers = {}\n",
    "best_estimators = pd.DataFrame(data=[], columns=['estimator', 'params', scoring])\n",
    "\n",
    "for est in estimators_list:\n",
    "    print(f\"estimator: {est['name']} --> \", end='')\n",
    "    gs = get_tuned_estimator(X_train, y_train, estimator=est['estimator'], param_dist=est['param_dist'], scoring=scoring)\n",
    "    params, score = gs.best_params_, gs.best_score_\n",
    "    best_estimators = pd.concat([best_estimators, pd.DataFrame([[est['name'], str(params.copy()), score]], columns=best_estimators.columns)], axis=0, ignore_index=True, sort=False)\n",
    "    classifiers[est['name']] = dict(estimator=gs.best_estimator_, hyperparameters=params.copy(), validation_metrics=None)\n",
    "    print(f'{scoring} = {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e9778-9154-4a92-be85-a1072aa05c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators.plot.bar(x='estimator', y=scoring, logy=False, ylim=[0, 1], grid=True, yticks=np.arange(0.05, 1, 0.05), figsize=(14, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ba5d4-d23b-44bc-ad5c-22b698da3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(best_estimators.to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6e0d0-98cd-404b-a970-d92920e2fc10",
   "metadata": {},
   "source": [
    "\n",
    "## 16. Avaliação dos classificadores selecionados  \n",
    "> A finalidade aqui é comparar o desempenho dos classificadores configurados com os hiperparâmetros selecionados, na base de teste.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bc110-172f-442a-a67b-3c38c1087926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "X_test, y_test = load_bases(type='test')\n",
    "X_test = data_preparation(transformers, X_test)\n",
    "X_test = pca.transform(X_test)\n",
    "target_names = ['SUCESSO', 'INSUCESSO']\n",
    "for clf in classifiers:\n",
    "    p = classifiers[clf]['estimator'].predict(X_test)\n",
    "    metrics, report = metrics_report(y_test, p, target_names=target_names, \n",
    "                                     title=f'Relatório de classificação para {clf}')\n",
    "    classifiers[clf]['validation_metrics'] = metrics\n",
    "    print(report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23806105-38fe-4326-9880-e2b1233f667b",
   "metadata": {},
   "source": [
    "## 17. Escolha do classificador\n",
    "> Escolha baseada nas métricas recall, precision, f1-score e accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f498d5-d7a3-434c-a430-9df3a76c16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'RFC'\n",
    "selected_classifier = classifiers[clf_name]['estimator']\n",
    "hyperparameters = classifiers[clf_name]['hyperparameters']\n",
    "validation_metrics = classifiers[clf_name]['validation_metrics']\n",
    "\n",
    "print(f'{clf_name} - Hiperparâmetros: {params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3653d58f-d470-4981-ae53-58d3f5dc433a",
   "metadata": {},
   "source": [
    "## 18. Armazenamento do modelo treinado em formato pickle\n",
    "> A finalidade é que o modelo treinado possa ser utilizado em outra aplicação a partir do carregamento do arquivo pickle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5735c9-11c2-4d95-808f-088408c41c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModel(object):\n",
    "    \n",
    "    def __init__(self, classifier, transformers, principal_components_analysis, \n",
    "                 validation_metrics, hyperparameters, sklearn_version=None):\n",
    "        \n",
    "        self.transformers = transformers\n",
    "        self.principal_components_analysis = principal_components_analysis\n",
    "        self.classifier = classifier\n",
    "        self.validation_metrics = validation_metrics\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.sklearn_version = sklearn_version\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4403872-66cc-4731-9680-d3e594251688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(object_model, filename):\n",
    "    with open(filename, 'wb') as fd:\n",
    "        pickle.dump(object_model, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83759b-23bd-4992-862c-7ec0e93c0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_model = MLModel(selected_classifier, transformers, pca, \n",
    "                       validation_metrics, hyperparameters, sklearn_version=sklearn.__version__)\n",
    "save_model(object_model, './trained_model/model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "981b7aa4-5539-48af-aa02-1ff548bf2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste(**tables):\n",
    "    data = transform_dataset(**tables, ylabel=True, ylabel_name='INSUCESSO')\n",
    "    data = data.drop(['NR_CONVENIO'], axis=1)\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef028316-ac4f-474f-b1dd-ebc5abbb9ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VL_REPASSE_CONV</th>\n",
       "      <th>VL_CONTRAPARTIDA_CONV</th>\n",
       "      <th>VALOR_EMENDA_CONVENIO</th>\n",
       "      <th>OBJETO_PROPOSTA</th>\n",
       "      <th>COD_ORGAO</th>\n",
       "      <th>COD_ORGAO_SUP</th>\n",
       "      <th>NATUREZA_JURIDICA</th>\n",
       "      <th>MODALIDADE</th>\n",
       "      <th>IDENTIF_PROPONENTE</th>\n",
       "      <th>COM_EMENDAS</th>\n",
       "      <th>INSUCESSO</th>\n",
       "      <th>CODIGO_IBGE</th>\n",
       "      <th>PRINCIPAL_PARLAMENTAR</th>\n",
       "      <th>PRINCIPAL_FORNECEDOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230000.00</td>\n",
       "      <td>80000.00</td>\n",
       "      <td>230000.00</td>\n",
       "      <td>AQUISIÇÃO DE MAQUINAS E EQUIPAMENTOS AGRÍCOLAS...</td>\n",
       "      <td>22000</td>\n",
       "      <td>22000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA MUNICIPAL</td>\n",
       "      <td>CONVENIO</td>\n",
       "      <td>90484320000157</td>\n",
       "      <td>SIM</td>\n",
       "      <td>0</td>\n",
       "      <td>4322186</td>\n",
       "      <td>CARLOS GOMES</td>\n",
       "      <td>02952689000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150000.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Projeto de capacitação de técnicos e produtore...</td>\n",
       "      <td>22000</td>\n",
       "      <td>22000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA ESTADUAL OU DO DISTRITO ...</td>\n",
       "      <td>CONVENIO</td>\n",
       "      <td>13937057000163</td>\n",
       "      <td>NAO</td>\n",
       "      <td>0</td>\n",
       "      <td>2927408</td>\n",
       "      <td>NAO APLICAVEL</td>\n",
       "      <td>NAO APLICAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231562.50</td>\n",
       "      <td>4726.50</td>\n",
       "      <td>231562.50</td>\n",
       "      <td>Aquisição de Patrulha Mecanizada para atender ...</td>\n",
       "      <td>22000</td>\n",
       "      <td>22000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA MUNICIPAL</td>\n",
       "      <td>CONTRATO DE REPASSE</td>\n",
       "      <td>15023971000124</td>\n",
       "      <td>SIM</td>\n",
       "      <td>0</td>\n",
       "      <td>5106307</td>\n",
       "      <td>JOSE MEDEIROS</td>\n",
       "      <td>12753213000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195000.00</td>\n",
       "      <td>27361.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Urbanização da Av. Cel. João Felipe na Sede do...</td>\n",
       "      <td>54000</td>\n",
       "      <td>54000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA MUNICIPAL</td>\n",
       "      <td>CONTRATO DE REPASSE</td>\n",
       "      <td>12459616000104</td>\n",
       "      <td>NAO</td>\n",
       "      <td>0</td>\n",
       "      <td>2309458</td>\n",
       "      <td>NAO APLICAVEL</td>\n",
       "      <td>06801930000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365714.29</td>\n",
       "      <td>4285.71</td>\n",
       "      <td>365714.29</td>\n",
       "      <td>Construção de dois Portais no município de Chã...</td>\n",
       "      <td>54000</td>\n",
       "      <td>54000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA MUNICIPAL</td>\n",
       "      <td>CONTRATO DE REPASSE</td>\n",
       "      <td>11049798000182</td>\n",
       "      <td>SIM</td>\n",
       "      <td>0</td>\n",
       "      <td>2604403</td>\n",
       "      <td>TADEU ALENCAR</td>\n",
       "      <td>NAO APLICAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73784</th>\n",
       "      <td>122000.00</td>\n",
       "      <td>28000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ESTRUTURAÇÃO DA REDE DE SERVIÇOS DO SISTEMA ÚN...</td>\n",
       "      <td>55000</td>\n",
       "      <td>55000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA MUNICIPAL</td>\n",
       "      <td>CONVENIO</td>\n",
       "      <td>18449132000160</td>\n",
       "      <td>NAO</td>\n",
       "      <td>0</td>\n",
       "      <td>3127107</td>\n",
       "      <td>NAO APLICAVEL</td>\n",
       "      <td>31022161000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73785</th>\n",
       "      <td>700000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>700000.00</td>\n",
       "      <td>AQUISIÇÃO DE EQUIPAMENTO E MATERIAL PERMANENTE...</td>\n",
       "      <td>36000</td>\n",
       "      <td>36000</td>\n",
       "      <td>ORGANIZAÇÃO DA SOCIEDADE CIVIL</td>\n",
       "      <td>CONVENIO</td>\n",
       "      <td>15170723000106</td>\n",
       "      <td>SIM</td>\n",
       "      <td>0</td>\n",
       "      <td>2927408</td>\n",
       "      <td>ANTONIO IMBASSAHY</td>\n",
       "      <td>33250713000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73786</th>\n",
       "      <td>365714.29</td>\n",
       "      <td>366.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Construção de Galeria para drenagem de águas p...</td>\n",
       "      <td>53000</td>\n",
       "      <td>53000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA MUNICIPAL</td>\n",
       "      <td>CONTRATO DE REPASSE</td>\n",
       "      <td>31796097000114</td>\n",
       "      <td>NAO</td>\n",
       "      <td>0</td>\n",
       "      <td>3203163</td>\n",
       "      <td>NAO APLICAVEL</td>\n",
       "      <td>10435044000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73787</th>\n",
       "      <td>250000.00</td>\n",
       "      <td>2958.05</td>\n",
       "      <td>250000.00</td>\n",
       "      <td>REFORMA DE UNIDADE DE ATENÇÃO ESPECIALIZADA EM...</td>\n",
       "      <td>36000</td>\n",
       "      <td>36000</td>\n",
       "      <td>ORGANIZAÇÃO DA SOCIEDADE CIVIL</td>\n",
       "      <td>CONTRATO DE REPASSE</td>\n",
       "      <td>1884775000130</td>\n",
       "      <td>SIM</td>\n",
       "      <td>0</td>\n",
       "      <td>4315909</td>\n",
       "      <td>COVATTI FILHO</td>\n",
       "      <td>07959756000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73788</th>\n",
       "      <td>243652.50</td>\n",
       "      <td>5100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Pavimentação com pedras irregulares.</td>\n",
       "      <td>22000</td>\n",
       "      <td>22000</td>\n",
       "      <td>ADMINISTRAÇÃO PÚBLICA MUNICIPAL</td>\n",
       "      <td>CONTRATO DE REPASSE</td>\n",
       "      <td>87612826000190</td>\n",
       "      <td>NAO</td>\n",
       "      <td>0</td>\n",
       "      <td>4310405</td>\n",
       "      <td>NAO APLICAVEL</td>\n",
       "      <td>08728051000146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73789 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VL_REPASSE_CONV  VL_CONTRAPARTIDA_CONV  VALOR_EMENDA_CONVENIO  \\\n",
       "0            230000.00               80000.00              230000.00   \n",
       "1            150000.00                 150.00                   0.00   \n",
       "2            231562.50                4726.50              231562.50   \n",
       "3            195000.00               27361.75                   0.00   \n",
       "4            365714.29                4285.71              365714.29   \n",
       "...                ...                    ...                    ...   \n",
       "73784        122000.00               28000.00                   0.00   \n",
       "73785        700000.00                   0.00              700000.00   \n",
       "73786        365714.29                 366.09                   0.00   \n",
       "73787        250000.00                2958.05              250000.00   \n",
       "73788        243652.50                5100.00                   0.00   \n",
       "\n",
       "                                         OBJETO_PROPOSTA  COD_ORGAO  \\\n",
       "0      AQUISIÇÃO DE MAQUINAS E EQUIPAMENTOS AGRÍCOLAS...      22000   \n",
       "1      Projeto de capacitação de técnicos e produtore...      22000   \n",
       "2      Aquisição de Patrulha Mecanizada para atender ...      22000   \n",
       "3      Urbanização da Av. Cel. João Felipe na Sede do...      54000   \n",
       "4      Construção de dois Portais no município de Chã...      54000   \n",
       "...                                                  ...        ...   \n",
       "73784  ESTRUTURAÇÃO DA REDE DE SERVIÇOS DO SISTEMA ÚN...      55000   \n",
       "73785  AQUISIÇÃO DE EQUIPAMENTO E MATERIAL PERMANENTE...      36000   \n",
       "73786  Construção de Galeria para drenagem de águas p...      53000   \n",
       "73787  REFORMA DE UNIDADE DE ATENÇÃO ESPECIALIZADA EM...      36000   \n",
       "73788               Pavimentação com pedras irregulares.      22000   \n",
       "\n",
       "       COD_ORGAO_SUP                                  NATUREZA_JURIDICA  \\\n",
       "0              22000                    ADMINISTRAÇÃO PÚBLICA MUNICIPAL   \n",
       "1              22000  ADMINISTRAÇÃO PÚBLICA ESTADUAL OU DO DISTRITO ...   \n",
       "2              22000                    ADMINISTRAÇÃO PÚBLICA MUNICIPAL   \n",
       "3              54000                    ADMINISTRAÇÃO PÚBLICA MUNICIPAL   \n",
       "4              54000                    ADMINISTRAÇÃO PÚBLICA MUNICIPAL   \n",
       "...              ...                                                ...   \n",
       "73784          55000                    ADMINISTRAÇÃO PÚBLICA MUNICIPAL   \n",
       "73785          36000                     ORGANIZAÇÃO DA SOCIEDADE CIVIL   \n",
       "73786          53000                    ADMINISTRAÇÃO PÚBLICA MUNICIPAL   \n",
       "73787          36000                     ORGANIZAÇÃO DA SOCIEDADE CIVIL   \n",
       "73788          22000                    ADMINISTRAÇÃO PÚBLICA MUNICIPAL   \n",
       "\n",
       "                MODALIDADE IDENTIF_PROPONENTE COM_EMENDAS  INSUCESSO  \\\n",
       "0                 CONVENIO     90484320000157         SIM          0   \n",
       "1                 CONVENIO     13937057000163         NAO          0   \n",
       "2      CONTRATO DE REPASSE     15023971000124         SIM          0   \n",
       "3      CONTRATO DE REPASSE     12459616000104         NAO          0   \n",
       "4      CONTRATO DE REPASSE     11049798000182         SIM          0   \n",
       "...                    ...                ...         ...        ...   \n",
       "73784             CONVENIO     18449132000160         NAO          0   \n",
       "73785             CONVENIO     15170723000106         SIM          0   \n",
       "73786  CONTRATO DE REPASSE     31796097000114         NAO          0   \n",
       "73787  CONTRATO DE REPASSE      1884775000130         SIM          0   \n",
       "73788  CONTRATO DE REPASSE     87612826000190         NAO          0   \n",
       "\n",
       "       CODIGO_IBGE PRINCIPAL_PARLAMENTAR PRINCIPAL_FORNECEDOR  \n",
       "0          4322186          CARLOS GOMES       02952689000180  \n",
       "1          2927408         NAO APLICAVEL        NAO APLICAVEL  \n",
       "2          5106307         JOSE MEDEIROS       12753213000335  \n",
       "3          2309458         NAO APLICAVEL       06801930000120  \n",
       "4          2604403         TADEU ALENCAR        NAO APLICAVEL  \n",
       "...            ...                   ...                  ...  \n",
       "73784      3127107         NAO APLICAVEL       31022161000100  \n",
       "73785      2927408     ANTONIO IMBASSAHY       33250713000243  \n",
       "73786      3203163         NAO APLICAVEL       10435044000106  \n",
       "73787      4315909         COVATTI FILHO       07959756000101  \n",
       "73788      4310405         NAO APLICAVEL       08728051000146  \n",
       "\n",
       "[73789 rows x 14 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste(convenios=convenios, proponentes=proponentes, emendas=emendas, emendas_convenios=emendas_convenios, fornecedores=fornecedores, movimento=movimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814c704-c0f7-4357-b875-102712c568ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
